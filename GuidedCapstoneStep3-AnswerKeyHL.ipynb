{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cf5CmXQCZyF1"
   },
   "source": [
    "# Guided Capstone Step 3 Exploratory Data Analysis - Answer Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6coRtYMknP8g"
   },
   "source": [
    "This is the third step in the Data Science Method. We introduced this topic in the last subunit. With Data Wrangling out of the way we can progress to the Exploratory Data Analysis section. In this exercise, you will learn to build data profiles and plots, including relationship plot and data correlation plot. You will also implement k-means clustering, complete clusters, and update data frame as a CSV file. Let's get started! \n",
    "\n",
    "\n",
    "  \n",
    "**The Data Science Method**  \n",
    "\n",
    "\n",
    "1.   Problem Identification \n",
    "\n",
    "2.   Data Wrangling \n",
    "  * Data Collection \n",
    "   * Data Organization\n",
    "  * Data Definition \n",
    "  * Data Cleaning\n",
    " \n",
    "3.   **Exploratory Data Analysis** \n",
    " * Build data profile tables and plots\n",
    "        - Outliers & Anomalies\n",
    " * Explore data relationships\n",
    " * Identification and creation of features\n",
    "\n",
    "4.   Pre-processing and Training Data Development\n",
    "  * Create dummy or indicator features for categorical variables\n",
    "  * Standardize the magnitude of numeric features\n",
    "  * Split into testing and training datasets\n",
    "  * Apply scaler to the testing set\n",
    "5.   Modeling \n",
    "  * Fit Models with Training Data Set\n",
    "  * Review Model Outcomes — Iterate over additional models as needed.\n",
    "  * Identify the Final Model\n",
    "\n",
    "6.   Documentation\n",
    "  * Review the Results\n",
    "  * Present and share your findings - storytelling\n",
    "  * Finalize Code \n",
    "  * Finalize Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0lE6m447SJ-"
   },
   "source": [
    "**<font color='teal'> Start by loading the necessary packages as we did in step 2 and printing out our current working directory just to confirm we are in the correct project directory. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59gUYHbOopAj"
   },
   "outputs": [],
   "source": [
    "#load python packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdnqcS6y7SKE"
   },
   "source": [
    "**<font color='teal'> If you need to change your path refer back to step 2 on how to do that. Then load the csv file you created in step 2, remember it should be saved inside your data subfolder and print the first five rows.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqNyb9Teo6HI"
   },
   "outputs": [],
   "source": [
    "file='updated_ski_data.csv'\n",
    "df=pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZDJfp-RlDZX"
   },
   "source": [
    "# Build data profile tables and plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkBHf9smZyGB"
   },
   "source": [
    "**<font color='teal'> Print out the summary stats table transposed to fit on the screen using the `describe()` function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i5sEVbbjZyGC"
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cofBcr2v7SKP"
   },
   "source": [
    "**<font color='teal'> Histograms are an excellent way to review the range and density of values for each numeric features in your data set and build data profiles. Plot the histograms for all numeric features and adjust the bins size to 25.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PX_gPWmAZyHW"
   },
   "outputs": [],
   "source": [
    "hist = df.hist(bins=25,figsize =(25,25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK7a8kFT7SKU"
   },
   "source": [
    "Look for similarities in the features that may indicate that they are duplicates or highly correlated features. Make a note of your findings and any other interesting insights you find about these numeric features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jDVOIne7SKV"
   },
   "source": [
    "**<font color='teal'> Okay, now you should be getting a sense for what the data look like. Let's create a barplot for the categorical features `Region` and `state` where the heights of the bars are the counts of each level in that variable. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpBGurdA7SKW"
   },
   "source": [
    "**<font color='teal'>State Levels Plot</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUBJ7wz87SKX"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "x = pd.DataFrame(df.state.value_counts())\n",
    "names = list(x.index)\n",
    "values = list(x.state)\n",
    "sns.barplot(x=values, y=names, palette=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LsSZ5O5R7SKZ"
   },
   "source": [
    "**<font color='teal'>Region Levels Plot</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bbbs0paw7SKa"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "x = pd.DataFrame(df.Region.value_counts())\n",
    "names = list(x.index)\n",
    "values = list(x.Region)\n",
    "sns.barplot(x=values, y=names, palette=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbjP0tTH7SKe"
   },
   "source": [
    "By reviewing the State and Regions counts plots you should notice that the Region feature is nearly identical to the state and therfore we can remove from the dataframe.**<font color='teal'> Remove the `Region` column using the drop function.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKmKsGZA7SKe"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['Region'],axis =1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnDVhE1-ZyGF"
   },
   "source": [
    "## Anamolies & Outliers - Review boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0y0CZmTY7SKi"
   },
   "source": [
    "**<font color='teal'> Print boxplot for every column</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gW3D-WlDZyGG"
   },
   "outputs": [],
   "source": [
    "boxplot = df.boxplot(grid=False, vert=False,fontsize=15, figsize=(12,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxbhlR5p7SKm"
   },
   "source": [
    "You need to create boxplots and  histograms to evaluate the data for potential outliers or data anomalies. Generally, outliers are defined as observations that differ significantly from the other values in the dataset or feature. \n",
    "\n",
    "Reviewing the distribution of values by column will help you  interpret this. Outliers are extreme values that fall far outside the mean and standard deviation of a set of observations. They  can mislead the training process in building machine learning models. Outliers may be real anomalies in the observations or artificial errors. \n",
    "\n",
    "One method for outlier analysis is extreme value analysis using a boxplot, which assumes a normal distribution. The figure below describes the components of a boxplot. Notice the outlier is the point outside the upper whisker end. \n",
    "\n",
    "![](AnnotatedBoxplot.png)  \n",
    "<font color='teal'>**Follow these steps:  \n",
    "\n",
    "1. Create boxplots - earlier step\n",
    "2. Apply outlier removal using the Interquartile range or replacement \n",
    "3. Review how many observations were removed**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9SMo7TK7SKn"
   },
   "outputs": [],
   "source": [
    "#Remove outliers based on IQR\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "dfno = df[~((df < (Q1 - 1.5 * IQR)) |(df> (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "boxplot = dfno.boxplot(grid=False, vert=False,fontsize=15, figsize=(12,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zf1W-AWM7SKq"
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "dfno.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0P2M5IXkl6fq"
   },
   "source": [
    "There are many ways to discover and remove outliers, and what counts as a sensible way of doing so depends on your problem, your methodology for solving that problem, and the nature of your data. \n",
    "\n",
    "Each method will have its merits and demerits. As we can see, in this instance, we've lost a great many observations! \n",
    "\n",
    "There is no hard and fast rule as to which outlier removal method is best in all cases, and you will have to exercise your good judgement in arriving at an appropriate method for your problem at hand. We will cover outlier removal in more depth in sections 7 (Data Wrangling) and 10 (Statistics for Exploratory Data Analysis) of the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ovv76_nQlUh1"
   },
   "source": [
    "There are many possible response variables you could have identified in the Step 1 guided capstone exercise. However, for the rest of this guided capstone project we will focus on increasing revenue by increasing the lift ticket prices and the number of days the resort is open per year. In this case, we need to investigate the expected lift ticket price for Big Mountain based on all the other given resort characteristics. In addition, we want to predict the number of days open each season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbCei31P7SKu"
   },
   "source": [
    "<font color='teal'>**Review the `AdultWeekday`,`AdultWeekend` response variable distributions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "og2uVb9rlUGB"
   },
   "outputs": [],
   "source": [
    "dfno['AdultWeekday'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1zIM_pu7SKz"
   },
   "outputs": [],
   "source": [
    "dfno['AdultWeekend'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-5AEMF67SK1"
   },
   "source": [
    "<font color='teal'>**Review the `daysOpenLastYear`,`projecteDaysOpen` response variable distributions**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7kE02U-7SK2"
   },
   "outputs": [],
   "source": [
    "dfno['daysOpenLastYear'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F0Skiiaj7SK4"
   },
   "outputs": [],
   "source": [
    "dfno['projectedDaysOpen'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-zGRx_dR7SK7"
   },
   "source": [
    "After reviewing these respons varible distributions, there doesn't appear to be any data issues to mitigate. Now, we move on to investigating feature relationship and interactions between the features the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5harOR1X-cZ"
   },
   "source": [
    "# Explore data relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FYeoHZG7SK9"
   },
   "source": [
    "<font color='teal'>**Create pairplots or what is commonly referred to as biplots**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMnIqr4B7SK-"
   },
   "outputs": [],
   "source": [
    "#pair plots\n",
    "g = sns.pairplot(dfno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoXbo4Wx7SLB"
   },
   "source": [
    "# Identification and creation of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gLI6E0IC7SLC"
   },
   "source": [
    "<font color='teal'>**Create a Pearson correlation heatmap**</font>\n",
    "\n",
    "Hint: such heatmaps are covered in Aiden's EDA article [here](https://medium.com/@aiden.dataminer/the-data-science-method-dsm-exploratory-data-analysis-bc84d4d8d3f9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wg0EQJkx7SLD"
   },
   "outputs": [],
   "source": [
    "corr = dfno.corr()\n",
    "corr.round(2).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAAEsooQ7SLF"
   },
   "source": [
    "When reviewing the Pearson correlation coefficient heat map you can see substantial differences in the correlations compared to the response variable(s) as well as in the features when compared to each other. The heatmap helps identify features that suffer from Multi-collinearity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3yPCf6S07SLH"
   },
   "source": [
    "<font color='teal'>**Use the correlation matrix displayed in the heatmap to select and remove collinear features. Remember to exclude the response variable(s) from the matrix to ensure they are retained in our final model development data set. Then select those features that are more than 95% correlated for removal.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvN8z0TC7SLI"
   },
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = dfno.drop(['AdultWeekday','AdultWeekend','daysOpenLastYear','projectedDaysOpen'], axis=1).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NaU2-oF07SLK"
   },
   "outputs": [],
   "source": [
    "print('Features selected to drop include',to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNJgUbqh7SLM"
   },
   "outputs": [],
   "source": [
    "print('Reduced dataframe size ',dfno.drop(dfno[to_drop], axis=1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K7Qfsl6l6gI"
   },
   "outputs": [],
   "source": [
    "# Let's drop base_elev\n",
    "dfno=dfno.drop(['base_elev'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1sGGsD67SLP"
   },
   "source": [
    "Now we address the feature creation piece of this step. We can create additional features through many methods such as: combining several features, grouping features into bins, or even by applying an unsupervised classification algorithm, such as Kmeans clustering and using the clusters as features in our model development dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KuvhY1k7SLQ"
   },
   "source": [
    "Run the next two cells below to create an Elbow plot. The Elbow plot is a diagnostic tool that helps you determine the number of clusters to include in your kmeans clustering implementation. In this example, the error between clusters and within clusters is compared for a range of 1 to 11 clusters, and it appears the elbow is between two and four, therefore we set the parameter k = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msM4LBBR7SLR"
   },
   "outputs": [],
   "source": [
    "#from sklearn.cluster import KMeans\n",
    "#x = dfno.drop(['Name','state'], axis =1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPP2xpLh7SLU"
   },
   "outputs": [],
   "source": [
    "#Error =[]\n",
    "#for i in range(1, 11):\n",
    "#   kmeans = KMeans(n_clusters = i).fit(x)\n",
    "#    kmeans.fit(x)\n",
    "#    Error.append(kmeans.inertia_)\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(range(1, 11), Error)\n",
    "#plt.title('Elbow method')\n",
    "#plt.xlabel('No of clusters')\n",
    "#plt.ylabel('Error')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KVIt60Ke7SLY"
   },
   "source": [
    "<font color='teal'>**Fit the kmeans algorithm with the k parameter set to three and plot the results.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9G1ujAbc7SLZ"
   },
   "outputs": [],
   "source": [
    "kmeans3 = KMeans(n_clusters=3)\n",
    "y_kmeans3 = kmeans3.fit_predict(x)\n",
    "plt.scatter(x[:, 0], x[:, 1], c=y_kmeans3, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans3.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZPrhHay7SLb"
   },
   "source": [
    "<font color='teal'>**Add the clusters to your dataframe as a new column to include in the next step and write the updated dataframe out as csv. Save the dataframe in the data folder and name it `step3_output.csv`.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdSoGtiQ7SLc"
   },
   "outputs": [],
   "source": [
    "dfno['clusters']=y_kmeans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OT7A3VpF7SLf"
   },
   "outputs": [],
   "source": [
    "dfno.to_csv('data/step3_output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tIG505nX7SLh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RtEspslPZyGY",
    "s0DokMkAZyGc",
    "2iuitnKcZyHS",
    "iAWQxougZyHW",
    "ThMTimlBZyHZ"
   ],
   "name": "GuidedCapstoneStep3-AnswerKey.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
