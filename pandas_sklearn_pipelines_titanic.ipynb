{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:45:29.768047Z",
     "start_time": "2017-09-06T10:45:29.756031Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelBinarizer, Imputer\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:08:39.772262Z",
     "start_time": "2017-09-06T10:08:38.009112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://gist.githubusercontent.com/braingineer/5d15057ac482ee0130b6d0e6f9cc9311/raw/d4eefaecc98b342ec578cf3512184556e8856750/titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:08:42.338840Z",
     "start_time": "2017-09-06T10:08:42.332844Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill in missing values (need to try move this into the pipeline)\n",
    "df['Age'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:20:13.693031Z",
     "start_time": "2017-09-06T10:20:13.683025Z"
    }
   },
   "outputs": [],
   "source": [
    "# use pandas sklearn to do some preprocessing\n",
    "\n",
    "# make pipeline for individual variables\n",
    "name_to_tfidf = Pipeline([ ('name_vect', CountVectorizer()) , ('name_tfidf', TfidfTransformer()) ])\n",
    "ticket_to_tfidf = Pipeline([ ('ticket_vect', CountVectorizer()) , ('ticket_tfidf', TfidfTransformer()) ])\n",
    "\n",
    "full_mapper = DataFrameMapper([\n",
    "    ('Name', name_to_tfidf ),\n",
    "    ('Ticket', ticket_to_tfidf ),\n",
    "    ('Sex', LabelBinarizer()),\n",
    "    (['Age', 'Fare'], None), # i tried to use Impute() but got an error\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:20:15.845170Z",
     "start_time": "2017-09-06T10:20:15.837159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# build full pipeline\n",
    "full_pipeline  = Pipeline([\n",
    "    ('mapper',full_mapper),\n",
    "    ('clf', SGDClassifier(n_iter=15, warm_start=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:26:09.196859Z",
     "start_time": "2017-09-06T10:26:09.186340Z"
    }
   },
   "outputs": [],
   "source": [
    "# determine full param search space (need to get the params for the mapper parts in here somehow)\n",
    "full_params = {'clf__alpha': [1e-2,1e-3,1e-4],\n",
    "               'clf__loss':['modified_huber','hinge'],\n",
    "               'clf__penalty':['l2','l1'],\n",
    "               # now set the params for the datamapper part of the pipeline\n",
    "               'mapper__features':[[\n",
    "                   ('Name',deepcopy(name_to_tfidf).set_params(name_vect__analyzer = ['char', 'char_wb'])),\n",
    "                   ('Ticket',deepcopy(ticket_to_tfidf).set_params(ticket_vect__analyzer = ['char', 'char_wb']))\n",
    "               ]]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:26:11.337851Z",
     "start_time": "2017-09-06T10:26:11.331847Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up grid search\n",
    "gs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:26:16.634508Z",
     "start_time": "2017-09-06T10:26:13.088713Z"
    }
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C9E25ECE40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C9E25ECE40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5A84EF422F964DCE9A58D1CBCA1BE656']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5A84EF422F964DCE9A58D1CBCA1BE656'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# do the fit\\ngs_clf.fit(df,df['Survived'])\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# do the fit\\ngs_clf.fit(df,df['Survived'])\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# do the fit\\ngs_clf.fit(df,df['Survived'])\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# do the fit\\ngs_clf.fit(df,df['Survived'])\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# do the fit\\ngs_clf.fit(df,df['Survived'])\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-35-541d18c33b30>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>\n        result = <ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>, result=<ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', 'import pandas as pd\\nfrom sklearn_pandas import D...earn.preprocessing import LabelBinarizer, Imputer', \"df = pd.read_csv('https://gist.githubusercontent...ec578cf3512184556e8856750/titanic.csv')\\ndf.head()\", \"# fill in missing values (need to try move this ...the pipeline)\\ndf['Age'].fillna(0, inplace = True)\", '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", 'import pandas as pd\\nfrom sklearn_pandas import D...LabelBinarizer, Imputer\\nfrom copy import deepcopy', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# build full pipeline\\nfull_pipeline  = Pipeline(...f', SGDClassifier(n_iter=15, warm_start=True))\\n])\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...', 'char_wb']))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...yzer = 'word'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", '# do the fit\\ngs_clf.fit(df,df[\\'Survived\\'])\\n\\nprin... %r\" % (param_name, best_parameters[param_name]))', ...], 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'NamespaceMagics': <class 'IPython.core.magics.namespace.NamespaceMagics'>, 'Out': {3:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 12: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 18: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 20: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 31: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', 'import pandas as pd\\nfrom sklearn_pandas import D...earn.preprocessing import LabelBinarizer, Imputer', \"df = pd.read_csv('https://gist.githubusercontent...ec578cf3512184556e8856750/titanic.csv')\\ndf.head()\", \"# fill in missing values (need to try move this ...the pipeline)\\ndf['Age'].fillna(0, inplace = True)\", '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", 'import pandas as pd\\nfrom sklearn_pandas import D...LabelBinarizer, Imputer\\nfrom copy import deepcopy', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# build full pipeline\\nfull_pipeline  = Pipeline(...f', SGDClassifier(n_iter=15, warm_start=True))\\n])\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...', 'char_wb']))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...yzer = 'word'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", '# do the fit\\ngs_clf.fit(df,df[\\'Survived\\'])\\n\\nprin... %r\" % (param_name, best_parameters[param_name]))', ...], 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'NamespaceMagics': <class 'IPython.core.magics.namespace.NamespaceMagics'>, 'Out': {3:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 12: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 18: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 20: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 31: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Andrew\\<ipython-input-35-541d18c33b30> in <module>()\n      1 # do the fit\n----> 2 gs_clf.fit(df,df['Survived'])\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns]\n        y = 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Sep  6 11:26:14 2017\nPID: 14736              Python 3.6.1: C:\\Users\\Andrew\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), verbose=0, parameters={'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e=True, tol=None, verbose=0, warm_start=True))])>\n        X_train =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y_train = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...e=True, tol=None, verbose=0, warm_start=True))])>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'mapper': {}}\n        name = 'mapper'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), weight=None, X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of ...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method DataFrameMapper.fit of DataFrameMa...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    191         for columns, transformers, options in self.built_features:\n    192             input_df = options.get('input_df', self.input_df)\n    193 \n    194             if transformers is not None:\n    195                 _call_fit(transformers.fit,\n--> 196                           self._get_col_subset(X, columns, input_df), y)\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        columns = 'Name'\n        input_df = False\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    197 \n    198         # handle features not explicitly selected\n    199         if self.built_default:  # not False and not None\n    200             _call_fit(self.built_default.fit,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\pipeline.py in _call_fit(fit_method=<bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **kwargs={})\n     19     or fit_transform method passed to it in isolation as _call_fit will not\n     20     distinguish TypeError due to incorrect number of arguments from\n     21     other TypeError\n     22     \"\"\"\n     23     try:\n---> 24         return fit_method(X, y, **kwargs)\n        fit_method = <bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        kwargs = {}\n     25     except TypeError:\n     26         # fit takes only one argument\n     27         return fit_method(X, **kwargs)\n     28 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'name_tfidf': {}, 'name_vect': {}}\n        name = 'name_vect'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), weight=None, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), fixed_vocab=False)\n    780         else:\n    781             # Add a new value when a new vocabulary item is seen\n    782             vocabulary = defaultdict()\n    783             vocabulary.default_factory = vocabulary.__len__\n    784 \n--> 785         analyze = self.build_analyzer()\n        analyze = undefined\n        self.build_analyzer = <bound method VectorizerMixin.build_analyzer of ...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n    786         j_indices = []\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in build_analyzer(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None))\n    265             return lambda doc: self._word_ngrams(\n    266                 tokenize(preprocess(self.decode(doc))), stop_words)\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n--> 270                              self.analyzer)\n        self.analyzer = ['char', 'char_wb']\n    271 \n    272     def _validate_vocabulary(self):\n    273         vocabulary = self.vocabulary\n    274         if vocabulary is not None:\n\nValueError: ['char', 'char_wb'] is not a valid tokenization scheme/analyzer\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 257, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 222, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py\", line 521, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\", line 196, in fit\n    self._get_col_subset(X, columns, input_df), y)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\pipeline.py\", line 24, in _call_fit\n    return fit_method(X, y, **kwargs)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 257, in fit\n    Xt, fit_params = self._fit(X, y, **fit_params)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 222, in _fit\n    **fit_params_steps[name])\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 589, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 869, in fit_transform\n    self.fixed_vocabulary_)\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 785, in _count_vocab\n    analyze = self.build_analyzer()\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 270, in build_analyzer\n    self.analyzer)\nValueError: ['char', 'char_wb'] is not a valid tokenization scheme/analyzer\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Sep  6 11:26:14 2017\nPID: 14736              Python 3.6.1: C:\\Users\\Andrew\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), verbose=0, parameters={'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e=True, tol=None, verbose=0, warm_start=True))])>\n        X_train =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y_train = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...e=True, tol=None, verbose=0, warm_start=True))])>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'mapper': {}}\n        name = 'mapper'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), weight=None, X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of ...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method DataFrameMapper.fit of DataFrameMa...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    191         for columns, transformers, options in self.built_features:\n    192             input_df = options.get('input_df', self.input_df)\n    193 \n    194             if transformers is not None:\n    195                 _call_fit(transformers.fit,\n--> 196                           self._get_col_subset(X, columns, input_df), y)\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        columns = 'Name'\n        input_df = False\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    197 \n    198         # handle features not explicitly selected\n    199         if self.built_default:  # not False and not None\n    200             _call_fit(self.built_default.fit,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\pipeline.py in _call_fit(fit_method=<bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **kwargs={})\n     19     or fit_transform method passed to it in isolation as _call_fit will not\n     20     distinguish TypeError due to incorrect number of arguments from\n     21     other TypeError\n     22     \"\"\"\n     23     try:\n---> 24         return fit_method(X, y, **kwargs)\n        fit_method = <bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        kwargs = {}\n     25     except TypeError:\n     26         # fit takes only one argument\n     27         return fit_method(X, **kwargs)\n     28 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'name_tfidf': {}, 'name_vect': {}}\n        name = 'name_vect'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), weight=None, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), fixed_vocab=False)\n    780         else:\n    781             # Add a new value when a new vocabulary item is seen\n    782             vocabulary = defaultdict()\n    783             vocabulary.default_factory = vocabulary.__len__\n    784 \n--> 785         analyze = self.build_analyzer()\n        analyze = undefined\n        self.build_analyzer = <bound method VectorizerMixin.build_analyzer of ...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n    786         j_indices = []\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in build_analyzer(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None))\n    265             return lambda doc: self._word_ngrams(\n    266                 tokenize(preprocess(self.decode(doc))), stop_words)\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n--> 270                              self.analyzer)\n        self.analyzer = ['char', 'char_wb']\n    271 \n    272     def _validate_vocabulary(self):\n    273         vocabulary = self.vocabulary\n    274         if vocabulary is not None:\n\nValueError: ['char', 'char_wb'] is not a valid tokenization scheme/analyzer\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Wed Sep  6 11:26:14 2017\nPID: 14736              Python 3.6.1: C:\\Users\\Andrew\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), verbose=0, parameters={'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e=True, tol=None, verbose=0, warm_start=True))])>\n        X_train =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y_train = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...e=True, tol=None, verbose=0, warm_start=True))])>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'mapper': {}}\n        name = 'mapper'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), weight=None, X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of ...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method DataFrameMapper.fit of DataFrameMa...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    191         for columns, transformers, options in self.built_features:\n    192             input_df = options.get('input_df', self.input_df)\n    193 \n    194             if transformers is not None:\n    195                 _call_fit(transformers.fit,\n--> 196                           self._get_col_subset(X, columns, input_df), y)\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        columns = 'Name'\n        input_df = False\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    197 \n    198         # handle features not explicitly selected\n    199         if self.built_default:  # not False and not None\n    200             _call_fit(self.built_default.fit,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\pipeline.py in _call_fit(fit_method=<bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **kwargs={})\n     19     or fit_transform method passed to it in isolation as _call_fit will not\n     20     distinguish TypeError due to incorrect number of arguments from\n     21     other TypeError\n     22     \"\"\"\n     23     try:\n---> 24         return fit_method(X, y, **kwargs)\n        fit_method = <bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        kwargs = {}\n     25     except TypeError:\n     26         # fit takes only one argument\n     27         return fit_method(X, **kwargs)\n     28 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'name_tfidf': {}, 'name_vect': {}}\n        name = 'name_vect'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), weight=None, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), fixed_vocab=False)\n    780         else:\n    781             # Add a new value when a new vocabulary item is seen\n    782             vocabulary = defaultdict()\n    783             vocabulary.default_factory = vocabulary.__len__\n    784 \n--> 785         analyze = self.build_analyzer()\n        analyze = undefined\n        self.build_analyzer = <bound method VectorizerMixin.build_analyzer of ...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n    786         j_indices = []\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in build_analyzer(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None))\n    265             return lambda doc: self._word_ngrams(\n    266                 tokenize(preprocess(self.decode(doc))), stop_words)\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n--> 270                              self.analyzer)\n        self.analyzer = ['char', 'char_wb']\n    271 \n    272     def _validate_vocabulary(self):\n    273         vocabulary = self.vocabulary\n    274         if vocabulary is not None:\n\nValueError: ['char', 'char_wb'] is not a valid tokenization scheme/analyzer\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-541d18c33b30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# do the fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x000001C9E25ECE40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x000001C9E25ECE40, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\A...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'5A84EF422F964DCE9A58D1CBCA1BE656']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'5A84EF422F964DCE9A58D1CBCA1BE656'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 9, 6, 10, 26, 13, 85712, tzinfo=tzutc()), 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'session': '5A84EF422F964DCE9A58D1CBCA1BE656', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'FB56CD96053B4D028F9A615462E1D6E8', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# do the fit\\ngs_clf.fit(df,df['Survived'])\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# do the fit\\ngs_clf.fit(df,df['Survived'])\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# do the fit\\ngs_clf.fit(df,df['Survived'])\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# do the fit\\ngs_clf.fit(df,df['Survived'])\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# do the fit\\ngs_clf.fit(df,df['Survived'])\", store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-35-541d18c33b30>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>)\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n   2807                 code = compiler(mod, cell_name, \"single\")\n-> 2808                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>\n        result = <ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>\n   2809                     return True\n   2810 \n   2811             # Flush softspace\n   2812             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>, result=<ExecutionResult object at 1c9ea190748, executio..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000001C9EA09C0C0, file \"<ipython-input-35-541d18c33b30>\", line 2>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', 'import pandas as pd\\nfrom sklearn_pandas import D...earn.preprocessing import LabelBinarizer, Imputer', \"df = pd.read_csv('https://gist.githubusercontent...ec578cf3512184556e8856750/titanic.csv')\\ndf.head()\", \"# fill in missing values (need to try move this ...the pipeline)\\ndf['Age'].fillna(0, inplace = True)\", '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", 'import pandas as pd\\nfrom sklearn_pandas import D...LabelBinarizer, Imputer\\nfrom copy import deepcopy', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# build full pipeline\\nfull_pipeline  = Pipeline(...f', SGDClassifier(n_iter=15, warm_start=True))\\n])\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...', 'char_wb']))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...yzer = 'word'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", '# do the fit\\ngs_clf.fit(df,df[\\'Survived\\'])\\n\\nprin... %r\" % (param_name, best_parameters[param_name]))', ...], 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'NamespaceMagics': <class 'IPython.core.magics.namespace.NamespaceMagics'>, 'Out': {3:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 12: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 18: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 20: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 31: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DataFrameMapper': <class 'sklearn_pandas.dataframe_mapper.DataFrameMapper'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'Imputer': <class 'sklearn.preprocessing.imputation.Imputer'>, 'In': ['', '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', 'import pandas as pd\\nfrom sklearn_pandas import D...earn.preprocessing import LabelBinarizer, Imputer', \"df = pd.read_csv('https://gist.githubusercontent...ec578cf3512184556e8856750/titanic.csv')\\ndf.head()\", \"# fill in missing values (need to try move this ...the pipeline)\\ndf['Age'].fillna(0, inplace = True)\", '# use pandas sklearn to do some preprocessing\\n\\nn...# i tried to use Impute() but got an error\\n    ])', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", 'import pandas as pd\\nfrom sklearn_pandas import D...LabelBinarizer, Imputer\\nfrom copy import deepcopy', \"# determine full param search space (need to get...er= 'char_wb'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# build full pipeline\\nfull_pipeline  = Pipeline(...f', SGDClassifier(n_iter=15, warm_start=True))\\n])\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...', 'char_wb']))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", \"# determine full param search space (need to get...yzer = 'word'))\\n               ]]\\n              }\", '# set up grid search\\ngs_clf = GridSearchCV(full_pipeline, full_params, n_jobs=-1)', \"# do the fit\\ngs_clf.fit(df,df['Survived'])\", '# do the fit\\ngs_clf.fit(df,df[\\'Survived\\'])\\n\\nprin... %r\" % (param_name, best_parameters[param_name]))', ...], 'LabelBinarizer': <class 'sklearn.preprocessing.label.LabelBinarizer'>, 'NamespaceMagics': <class 'IPython.core.magics.namespace.NamespaceMagics'>, 'Out': {3:    PassengerId  Survived  Pclass  \\\n0           ...    0            373450   8.0500   NaN        S  , 12: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 18: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 20: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 25: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), 31: GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0)}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\Andrew\\<ipython-input-35-541d18c33b30> in <module>()\n      1 # do the fit\n----> 2 gs_clf.fit(df,df['Survived'])\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...train_score=True,\n       scoring=None, verbose=0), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns]\n        y = 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Wed Sep  6 11:26:14 2017\nPID: 14736              Python 3.6.1: C:\\Users\\Andrew\\Miniconda3\\python.exe\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]),      PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], 0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, {'score': <function _passthrough_scorer>}, array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), 0, {'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n0         ...          NaN        Q  \n\n[891 rows x 12 columns], y=0      0\n1      1\n2      1\n3      1\n4      0\n5  ...90    0\nName: Survived, Length: 891, dtype: int64, scorer={'score': <function _passthrough_scorer>}, train=array([284, 285, 287, 292, 293, 294, 295, 296, 2...    882, 883, 884, 885, 886, 887, 888, 889, 890]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...90, 291, 298, 299, 300, 301, 303, 305, 306, 307]), verbose=0, parameters={'clf__alpha': 0.01, 'clf__loss': 'modified_huber', 'clf__penalty': 'l2', 'mapper__features': [('Name', Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))])), ('Ticket', Pipeline(memory=None,\n     steps=[('ticket_vect'...th_idf=True, sublinear_tf=False, use_idf=True))]))]}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...e=True, tol=None, verbose=0, warm_start=True))])>\n        X_train =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y_train = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...e=True, tol=None, verbose=0, warm_start=True))])>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('mapper', Dat...le=True, tol=None, verbose=0, warm_start=True))]), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'mapper': {}}\n        name = 'mapper'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), None,      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), weight=None, X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method TransformerMixin.fit_transform of ...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\base.py in fit_transform(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method DataFrameMapper.fit of DataFrameMa...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py in fit(self=DataFrameMapper(default=False, df_out=False,\n   ...True))]))],\n        input_df=False, sparse=False), X=     PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns], y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    191         for columns, transformers, options in self.built_features:\n    192             input_df = options.get('input_df', self.input_df)\n    193 \n    194             if transformers is not None:\n    195                 _call_fit(transformers.fit,\n--> 196                           self._get_col_subset(X, columns, input_df), y)\n        self._get_col_subset = <bound method DataFrameMapper._get_col_subset of...rue))]))],\n        input_df=False, sparse=False)>\n        X =      PassengerId  Survived  Pclass  \\\n284       ...          NaN        Q  \n\n[594 rows x 12 columns]\n        columns = 'Name'\n        input_df = False\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    197 \n    198         # handle features not explicitly selected\n    199         if self.built_default:  # not False and not None\n    200             _call_fit(self.built_default.fit,\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn_pandas\\pipeline.py in _call_fit(fit_method=<bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **kwargs={})\n     19     or fit_transform method passed to it in isolation as _call_fit will not\n     20     distinguish TypeError due to incorrect number of arguments from\n     21     other TypeError\n     22     \"\"\"\n     23     try:\n---> 24         return fit_method(X, y, **kwargs)\n        fit_method = <bound method Pipeline.fit of Pipeline(memory=No...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        kwargs = {}\n     25     except TypeError:\n     26         # fit takes only one argument\n     27         return fit_method(X, **kwargs)\n     28 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...h_idf=True, sublinear_tf=False, use_idf=True))])>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('name_vect', ...th_idf=True, sublinear_tf=False, use_idf=True))]), X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'name_tfidf': {}, 'name_vect': {}}\n        name = 'name_vect'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x000001934482F378>), *args=(CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), None, array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), weight=None, X=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64, **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n        X = array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object)\n        y = 284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in fit_transform(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), y=284    0\n285    0\n287    0\n292    0\n293    0\n294...90    0\nName: Survived, Length: 594, dtype: int64)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in _count_vocab(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), raw_documents=array(['Smith, Mr. Richard William', 'Stankovic,...ll',\n       'Dooley, Mr. Patrick'], dtype=object), fixed_vocab=False)\n    780         else:\n    781             # Add a new value when a new vocabulary item is seen\n    782             vocabulary = defaultdict()\n    783             vocabulary.default_factory = vocabulary.__len__\n    784 \n--> 785         analyze = self.build_analyzer()\n        analyze = undefined\n        self.build_analyzer = <bound method VectorizerMixin.build_analyzer of ...\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)>\n    786         j_indices = []\n    787         indptr = _make_int_array()\n    788         values = _make_int_array()\n    789         indptr.append(0)\n\n...........................................................................\nC:\\Users\\Andrew\\Miniconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py in build_analyzer(self=CountVectorizer(analyzer=['char', 'char_wb'], bi...)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None))\n    265             return lambda doc: self._word_ngrams(\n    266                 tokenize(preprocess(self.decode(doc))), stop_words)\n    267 \n    268         else:\n    269             raise ValueError('%s is not a valid tokenization scheme/analyzer' %\n--> 270                              self.analyzer)\n        self.analyzer = ['char', 'char_wb']\n    271 \n    272     def _validate_vocabulary(self):\n    273         vocabulary = self.vocabulary\n    274         if vocabulary is not None:\n\nValueError: ['char', 'char_wb'] is not a valid tokenization scheme/analyzer\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# do the fit\n",
    "gs_clf.fit(df,df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:34:15.053870Z",
     "start_time": "2017-09-06T10:34:15.035351Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-e54ce5212362>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best score: %0.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t%s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_parameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % gs_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gs_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(full_params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-06T10:34:17.597411Z",
     "start_time": "2017-09-06T10:34:17.553845Z"
    }
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-921b08d2e221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# look at f1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Survived'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \"\"\"\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_check_is_fitted\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                  % (type(self).__name__, method_name))\n\u001b[0;32m    448\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "# look at f1\n",
    "y = gs_clf.predict(df)\n",
    "print(classification_report(y, df['Survived']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
